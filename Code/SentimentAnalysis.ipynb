{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "504ed2f5",
   "metadata": {},
   "source": [
    "Reference: https://github.com/chuachinhon/practical_nlp/blob/master/notebooks/1.0_speech_sentiment_cch.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2795cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import PlaintextCorpusReader\n",
    "import matplotlib as mpl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "5293c4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file directory\n",
    "file_directory = '..\\\\Dataset\\\\'\n",
    "\n",
    "# Read a single file \n",
    "with open(file_directory + '2022_eng.txt', 'r', encoding=\"utf8\") as file_to_read:\n",
    "    df = file_to_read.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c7098b",
   "metadata": {},
   "source": [
    "**Issues**\n",
    "- Hugging Face pipeline can only deal with max 512 tokens. Our paragraphs are too long and hence, need to convert to sentences for hugging face."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "abf27234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into dataframes, split by sentences\n",
    "df = (pd.DataFrame(df.split(\"\\n\\n\"))).rename(columns={0: \"Paras\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "e10ceda5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\n\", \" \", text) #replace \"\\n\" with \" \"\n",
    "    text = re.sub(r\"\\W\", \" \", text) #replaces non-word characters like ',' with \" \"\n",
    "    text = re.sub(r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text) #removes digits e.g. 16 years >> years\n",
    "    text = text.strip(\" \")\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "df[\"Clean_Text\"] = df['Paras'].map(lambda text: clean_text(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59920f19",
   "metadata": {},
   "source": [
    "**Sentiment Analysis**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "e5dae19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df['Clean_Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "8a16535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_sentiment = pipeline(\"sentiment-analysis\", model= \"distilbert-base-uncased-finetuned-sst-2-english\" )  \n",
    "#using 'sentiment-analysis'same as \"text-classification\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "17ae6438",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (605 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (605) must match the size of tensor b (512) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_19652/1553090226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Sentiment\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnlp_sentiment\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[0mIf\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mtop_k\u001b[0m\u001b[0;31m`\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mused\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone\u001b[0m \u001b[0msuch\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mreturned\u001b[0m \u001b[0mper\u001b[0m \u001b[0mlabel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \"\"\"\n\u001b[1;32m--> 138\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m         \u001b[1;31m# TODO try and retrieve it in a nicer way from _sanitize_parameters.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[0m_legacy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"top_k\"\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1054\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                 )\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfinal_iterator\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   1054\u001b[0m                     \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpreprocess_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mforward_params\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpostprocess_params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m                 )\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0moutput\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfinal_iterator\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0moutputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# We're out of items within a batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[0mprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m         \u001b[1;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\pt_utils.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;31m# We're out of items within a batch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m         \u001b[0mitem\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 112\u001b[1;33m         \u001b[0mprocessed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    113\u001b[0m         \u001b[1;31m# We now have a batch of \"inferred things\".\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    114\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloader_batch_size\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\base.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[0;32m    981\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0minference_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    982\u001b[0m                     \u001b[0mmodel_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 983\u001b[1;33m                     \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mforward_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    984\u001b[0m                     \u001b[0mmodel_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ensure_tensor_on_device\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"cpu\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    985\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\pipelines\\text_classification.py\u001b[0m in \u001b[0;36m_forward\u001b[1;34m(self, model_inputs)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mmodel_inputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpostprocess\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel_outputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunction_to_apply\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtop_k\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_legacy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    747\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 749\u001b[1;33m         distilbert_output = self.distilbert(\n\u001b[0m\u001b[0;32m    750\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    751\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    566\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    567\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minputs_embeds\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 568\u001b[1;33m             \u001b[0minputs_embeds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    569\u001b[0m         return self.transformer(\n\u001b[0;32m    570\u001b[0m             \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1131\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\transformers\\models\\distilbert\\modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input_ids)\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[0mposition_embeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mposition_embeddings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mposition_ids\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    131\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 132\u001b[1;33m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mword_embeddings\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mposition_embeddings\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    133\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLayerNorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m         \u001b[0membeddings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# (bs, max_seq_length, dim)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (605) must match the size of tensor b (512) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "df[\"Sentiment\"] = nlp_sentiment(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c63360c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pipeline's sentiment analysis output that consists of a label and a score into separate columns\n",
    "\n",
    "df['Sentiment_Label'] = [x.get('label') for x in df['Sentiment']]\n",
    "df['Sentiment_Score'] = [x.get('score') for x in df['Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "399ccee2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b175249",
   "metadata": {},
   "source": [
    "### Sentiment Analysis Attempt 2\n",
    "- Overcoming the issues on max length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "96bb02a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the file directory\n",
    "file_directory = '..\\\\Dataset\\\\'\n",
    "\n",
    "# Read a single file \n",
    "with open(file_directory + '2022_eng.txt', 'r', encoding=\"utf8\") as file_to_read:\n",
    "    df = file_to_read.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "806c1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert into dataframes, split by paragraphs\n",
    "df = (pd.DataFrame(df.split(\"\\n\\n\"))).rename(columns={0: \"Paragraphs\"})\n",
    "\n",
    "#Create new column to store Paragraph Numbers \n",
    "df['ParasNo'] = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "f8b2993f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Paragraphs</th>\n",
       "      <th>ParasNo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>My fellow Singaporeans</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Good evening.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>COVID-19\\nWe have come a long way in our fight...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In many other countries, when a wave happens, ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Thus far, we have had fewer than 1,600 COVID-1...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Paragraphs  ParasNo\n",
       "0                             My fellow Singaporeans        0\n",
       "1                                      Good evening.        1\n",
       "2  COVID-19\\nWe have come a long way in our fight...        2\n",
       "3  In many other countries, when a wave happens, ...        3\n",
       "4  Thus far, we have had fewer than 1,600 COVID-1...        4"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1e5cad12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "# return list from series of comma-separated strings\n",
    "def chainer(s):\n",
    "    return list(chain.from_iterable(s.str.split('.')))\n",
    "\n",
    "# calculate lengths of splits using full stops as we are looking for sentences\n",
    "lens = df['Paragraphs'].str.split('.').map(len)\n",
    "\n",
    "# create new dataframe, repeating or chaining as appropriate\n",
    "df = pd.DataFrame({'ParasNo': np.repeat(df['ParasNo'], lens),\n",
    "                    'Sentences': chainer(df['Paragraphs'])}) \n",
    "\n",
    "df.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "819345b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParasNo</th>\n",
       "      <th>Sentences</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My fellow Singaporeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>COVID-19\\nWe have come a long way in our fight...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>We are now learning to live with the virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>628</th>\n",
       "      <td>96</td>\n",
       "      <td>But with your trust, we can come through what...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>96</td>\n",
       "      <td>With your support, we can turn hopes and drea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>630</th>\n",
       "      <td>96</td>\n",
       "      <td>Not just for now, not just for ourselves, but...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>631</th>\n",
       "      <td>96</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>632</th>\n",
       "      <td>97</td>\n",
       "      <td>Thank you and good night!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>633 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ParasNo                                          Sentences\n",
       "0          0                             My fellow Singaporeans\n",
       "1          1                                       Good evening\n",
       "2          1                                                   \n",
       "3          2  COVID-19\\nWe have come a long way in our fight...\n",
       "4          2         We are now learning to live with the virus\n",
       "..       ...                                                ...\n",
       "628       96   But with your trust, we can come through what...\n",
       "629       96   With your support, we can turn hopes and drea...\n",
       "630       96   Not just for now, not just for ourselves, but...\n",
       "631       96                                                   \n",
       "632       97                          Thank you and good night!\n",
       "\n",
       "[633 rows x 2 columns]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "db79064e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pre-processing\n",
    "\n",
    "#Drop rows with empty strings \n",
    "df.drop(index=df[df['Sentences'] == ''].index, inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"\\n\", \" \", text) #replace \"\\n\" with \" \"\n",
    "    text = re.sub(r\"\\W\", \" \", text) #replaces non-word characters like ',' with \" \"\n",
    "    text = re.sub(r\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", text) #removes digits e.g. 16 years >> years\n",
    "    text = text.strip(\" \")\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)\n",
    "    return text\n",
    "\n",
    "df[\"Clean_Text\"] = df['Sentences'].map(lambda text: clean_text(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "6ccbbbe7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParasNo</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Clean_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My fellow Singaporeans</td>\n",
       "      <td>my fellow singaporeans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good evening</td>\n",
       "      <td>good evening</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>COVID-19\\nWe have come a long way in our fight...</td>\n",
       "      <td>covid we have come a long way in our fight aga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>We are now learning to live with the virus</td>\n",
       "      <td>we are now learning to live with the virus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>With each infection wave, we have managed the...</td>\n",
       "      <td>with each infection wave  we have managed the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParasNo                                          Sentences  \\\n",
       "0        0                             My fellow Singaporeans   \n",
       "1        1                                       Good evening   \n",
       "2        2  COVID-19\\nWe have come a long way in our fight...   \n",
       "3        2         We are now learning to live with the virus   \n",
       "4        2   With each infection wave, we have managed the...   \n",
       "\n",
       "                                          Clean_Text  \n",
       "0                             my fellow singaporeans  \n",
       "1                                       good evening  \n",
       "2  covid we have come a long way in our fight aga...  \n",
       "3         we are now learning to live with the virus  \n",
       "4  with each infection wave  we have managed the ...  "
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35242b5c",
   "metadata": {},
   "source": [
    "Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "29b1f992",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = list(df['Clean_Text'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "916fc170",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp_sentiment = pipeline(\"sentiment-analysis\", model = \"distilbert-base-uncased-finetuned-sst-2-english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a8f560f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df[\"Sentiment\"] = nlp_sentiment(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ee5d0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract pipeline's sentiment analysis output that consists of a label and a score into separate columns\n",
    "\n",
    "df['Sentiment_Label'] = [x.get('label') for x in df['Sentiment']]\n",
    "df['Sentiment_Score'] = [x.get('score') for x in df['Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "b70ef244",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParasNo</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>My fellow Singaporeans</td>\n",
       "      <td>my fellow singaporeans</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9980775117874...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good evening</td>\n",
       "      <td>good evening</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9998613595962...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>COVID-19\\nWe have come a long way in our fight...</td>\n",
       "      <td>covid we have come a long way in our fight aga...</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9577266573905...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.957727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>We are now learning to live with the virus</td>\n",
       "      <td>we are now learning to live with the virus</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9938626289367...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.993863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>With each infection wave, we have managed the...</td>\n",
       "      <td>with each infection wave  we have managed the ...</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9479452967643...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.947945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>96</td>\n",
       "      <td>I have given you my take of what we can achie...</td>\n",
       "      <td>i have given you my take of what we can achiev...</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9860721230506...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.986072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>538</th>\n",
       "      <td>96</td>\n",
       "      <td>But with your trust, we can come through what...</td>\n",
       "      <td>but with your trust  we can come through whate...</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9050359129905...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.905036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>539</th>\n",
       "      <td>96</td>\n",
       "      <td>With your support, we can turn hopes and drea...</td>\n",
       "      <td>with your support  we can turn hopes and dream...</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9996213912963...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>540</th>\n",
       "      <td>96</td>\n",
       "      <td>Not just for now, not just for ourselves, but...</td>\n",
       "      <td>not just for now  not just for ourselves  but ...</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9988539218902...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.998854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>97</td>\n",
       "      <td>Thank you and good night!</td>\n",
       "      <td>thank you and good night</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9998629093170...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.999863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>542 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ParasNo                                          Sentences  \\\n",
       "0          0                             My fellow Singaporeans   \n",
       "1          1                                       Good evening   \n",
       "2          2  COVID-19\\nWe have come a long way in our fight...   \n",
       "3          2         We are now learning to live with the virus   \n",
       "4          2   With each infection wave, we have managed the...   \n",
       "..       ...                                                ...   \n",
       "537       96   I have given you my take of what we can achie...   \n",
       "538       96   But with your trust, we can come through what...   \n",
       "539       96   With your support, we can turn hopes and drea...   \n",
       "540       96   Not just for now, not just for ourselves, but...   \n",
       "541       97                          Thank you and good night!   \n",
       "\n",
       "                                            Clean_Text  \\\n",
       "0                               my fellow singaporeans   \n",
       "1                                         good evening   \n",
       "2    covid we have come a long way in our fight aga...   \n",
       "3           we are now learning to live with the virus   \n",
       "4    with each infection wave  we have managed the ...   \n",
       "..                                                 ...   \n",
       "537  i have given you my take of what we can achiev...   \n",
       "538  but with your trust  we can come through whate...   \n",
       "539  with your support  we can turn hopes and dream...   \n",
       "540  not just for now  not just for ourselves  but ...   \n",
       "541                           thank you and good night   \n",
       "\n",
       "                                             Sentiment Sentiment_Label  \\\n",
       "0    {'label': 'POSITIVE', 'score': 0.9980775117874...        POSITIVE   \n",
       "1    {'label': 'POSITIVE', 'score': 0.9998613595962...        POSITIVE   \n",
       "2    {'label': 'POSITIVE', 'score': 0.9577266573905...        POSITIVE   \n",
       "3    {'label': 'POSITIVE', 'score': 0.9938626289367...        POSITIVE   \n",
       "4    {'label': 'POSITIVE', 'score': 0.9479452967643...        POSITIVE   \n",
       "..                                                 ...             ...   \n",
       "537  {'label': 'POSITIVE', 'score': 0.9860721230506...        POSITIVE   \n",
       "538  {'label': 'POSITIVE', 'score': 0.9050359129905...        POSITIVE   \n",
       "539  {'label': 'POSITIVE', 'score': 0.9996213912963...        POSITIVE   \n",
       "540  {'label': 'POSITIVE', 'score': 0.9988539218902...        POSITIVE   \n",
       "541  {'label': 'POSITIVE', 'score': 0.9998629093170...        POSITIVE   \n",
       "\n",
       "     Sentiment_Score  \n",
       "0           0.998078  \n",
       "1           0.999861  \n",
       "2           0.957727  \n",
       "3           0.993863  \n",
       "4           0.947945  \n",
       "..               ...  \n",
       "537         0.986072  \n",
       "538         0.905036  \n",
       "539         0.999621  \n",
       "540         0.998854  \n",
       "541         0.999863  \n",
       "\n",
       "[542 rows x 6 columns]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "70a868f5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSITIVE    328\n",
       "NEGATIVE    214\n",
       "Name: Sentiment_Label, dtype: int64"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Sentiment_Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8c5bb55",
   "metadata": {},
   "source": [
    "Not sure if the below is alright.\n",
    "Each sentence has a sentiment label and score. I think that the score tells you how positive or negative it is.\n",
    "E.g. Sentiment_Label = Positive and Sentiment_Score = 0.957 means it is very very positive ; \n",
    "E.g. Sentiment_Label = Negative and Sentiment_Score = 0.788761 means it is very negative.\n",
    "\n",
    "Basically, if a paragraph has 5 sentences e.g. Paragraph 2, what I am doing is:\n",
    "1. Calculate how positive each sentence is. This entails:\n",
    "- Finding out which are the negative sentence \n",
    "- Then derive how positive it is\n",
    "- E.g., Para 2, Sentence 5. Since it is 0.788761 negative, it is 1-0.788.. = 0.21.. positive \n",
    "\n",
    "2. Thereafter, I will take the average of the scores to derive how positive of negative a paragraph is.\n",
    "The existing threshold used is >= 0.5 for positive and <0.5 for negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "7f412d5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ParasNo</th>\n",
       "      <th>Sentences</th>\n",
       "      <th>Clean_Text</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Sentiment_Label</th>\n",
       "      <th>Sentiment_Score</th>\n",
       "      <th>Positive_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>COVID-19\\nWe have come a long way in our fight...</td>\n",
       "      <td>covid we have come a long way in our fight aga...</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9577266573905...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.957727</td>\n",
       "      <td>0.957727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>We are now learning to live with the virus</td>\n",
       "      <td>we are now learning to live with the virus</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9938626289367...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.993863</td>\n",
       "      <td>0.993863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>With each infection wave, we have managed the...</td>\n",
       "      <td>with each infection wave  we have managed the ...</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.9479452967643...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.947945</td>\n",
       "      <td>0.947945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2</td>\n",
       "      <td>The latest, the Omicron BA</td>\n",
       "      <td>the latest  the omicron ba</td>\n",
       "      <td>{'label': 'POSITIVE', 'score': 0.6443324685096...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>0.644332</td>\n",
       "      <td>0.644332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2</td>\n",
       "      <td>5 wave, is now subsiding</td>\n",
       "      <td>wave  is now subsiding</td>\n",
       "      <td>{'label': 'NEGATIVE', 'score': 0.7887611389160...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>0.788761</td>\n",
       "      <td>0.211239</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ParasNo                                          Sentences  \\\n",
       "2        2  COVID-19\\nWe have come a long way in our fight...   \n",
       "3        2         We are now learning to live with the virus   \n",
       "4        2   With each infection wave, we have managed the...   \n",
       "5        2                         The latest, the Omicron BA   \n",
       "6        2                           5 wave, is now subsiding   \n",
       "\n",
       "                                          Clean_Text  \\\n",
       "2  covid we have come a long way in our fight aga...   \n",
       "3         we are now learning to live with the virus   \n",
       "4  with each infection wave  we have managed the ...   \n",
       "5                         the latest  the omicron ba   \n",
       "6                             wave  is now subsiding   \n",
       "\n",
       "                                           Sentiment Sentiment_Label  \\\n",
       "2  {'label': 'POSITIVE', 'score': 0.9577266573905...        POSITIVE   \n",
       "3  {'label': 'POSITIVE', 'score': 0.9938626289367...        POSITIVE   \n",
       "4  {'label': 'POSITIVE', 'score': 0.9479452967643...        POSITIVE   \n",
       "5  {'label': 'POSITIVE', 'score': 0.6443324685096...        POSITIVE   \n",
       "6  {'label': 'NEGATIVE', 'score': 0.7887611389160...        NEGATIVE   \n",
       "\n",
       "   Sentiment_Score  Positive_Score  \n",
       "2         0.957727        0.957727  \n",
       "3         0.993863        0.993863  \n",
       "4         0.947945        0.947945  \n",
       "5         0.644332        0.644332  \n",
       "6         0.788761        0.211239  "
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For illustration - can be removed later on\n",
    "df[df['ParasNo']==2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "f5e1293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create new column to store positive scores\n",
    "df['Positive_Score'] = df['Sentiment_Score']\n",
    "\n",
    "#Update the 'positive scores' for rows of negative sentiment \n",
    "mask = (df['Sentiment_Label'] == 'NEGATIVE')\n",
    "df.loc[mask, 'Positive_Score'] = 1 - df['Sentiment_Score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "9dcb8557",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the average of the sentence scores and store in a new dataframe\n",
    "results = df.groupby(['ParasNo']).mean('Positive_Score').drop(columns='Sentiment_Score',inplace=True)\n",
    "#Assign Sentiment Label for each paragraph where sentiment is positive if score >= 0.50, and negative otherwise. \n",
    "results['Paragraph_Sentiment_Label'] = np.where(results['Positive_Score']>=0.50, \"POSITIVE\",\"NEGATIVE\")\n",
    "\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "5977b6ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POSITIVE    66\n",
       "NEGATIVE    32\n",
       "Name: Paragraph_Sentiment_Label, dtype: int64"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['Paragraph_Sentiment_Label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
